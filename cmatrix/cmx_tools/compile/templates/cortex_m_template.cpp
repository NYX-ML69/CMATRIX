/*
 * Generated inference code for Cortex-M target
 * Model: $model_name
 * Target: $target
 * Generated by cmx_tools
 */

$includes
#include <cmatrix.hpp>
#include <arm_math.h>
#include <cmsis_os.h>

$defines

// Memory alignment for Cortex-M
#define ALIGN_CORTEX_M __attribute__((aligned(ALIGNMENT)))

/*
 * Static tensor declarations
 * No dynamic allocation - all tensors allocated at compile time
 */
$tensor_declarations

// Model weights and biases (stored in flash)
static const float model_weights[] ALIGN_CORTEX_M = {
    // Weights will be populated during code generation
    0.0f
};

static const float model_biases[] ALIGN_CORTEX_M = {
    // Biases will be populated during code generation
    0.0f
};

// Working memory buffers
static float input_buffer[1024] ALIGN_CORTEX_M;
static float output_buffer[1024] ALIGN_CORTEX_M;
static float temp_buffer[2048] ALIGN_CORTEX_M;

/*
 * Layer implementation functions
 */
$layer_functions

/*
 * Model initialization
 */
int ${model_name}_init(void) {
    // Initialize CMSIS-DSP
    arm_status status = ARM_MATH_SUCCESS;
    
    // Initialize cmx_core library
    if (cmx_init() != CMX_SUCCESS) {
        return -1;
    }
    
    // Clear buffers
    memset(input_buffer, 0, sizeof(input_buffer));
    memset(output_buffer, 0, sizeof(output_buffer));
    memset(temp_buffer, 0, sizeof(temp_buffer));
    
    return 0;
}

/*
 * Model cleanup
 */
void ${model_name}_cleanup(void) {
    cmx_shutdown();
}

/*
 * Main inference function
 */
int ${model_name}_inference(const float* input, float* output) {
    // Validate inputs
    if (input == NULL || output == NULL) {
        return -1;
    }
    
    // Copy input to working buffer
    memcpy(input_buffer, input, ${model_name}_get_input_size() * sizeof(float));
    
    // Execute inference pipeline
$inference_loop
    
    // Copy result to output buffer
    memcpy(output, output_buffer, ${model_name}_get_output_size() * sizeof(float));
    
    return 0;
}

/*
 * Model metadata functions
 */
const char* ${model_name}_get_version(void) {
    return "1.0.0";
}

int ${model_name}_get_input_size(void) {
    return 224 * 224 * 3; // Will be replaced with actual size
}

int ${model_name}_get_output_size(void) {
    return 1000; // Will be replaced with actual size
}

/*
 * Main function for standalone execution
 */
int main(void) {
    // Initialize system
    SystemInit();
    
    // Initialize model
    if (${model_name}_init() != 0) {
        printf("Failed to initialize model\\n");
        return -1;
    }
    
    // Allocate input/output on stack
    float input[${model_name}_get_input_size()];
    float output[${model_name}_get_output_size()];
    
    // Initialize with dummy data for testing
    for (int i = 0; i < ${model_name}_get_input_size(); i++) {
        input[i] = 0.1f * (i % 10);
    }
    
    // Run inference
    printf("Running inference...\\n");
    uint32_t start_time = HAL_GetTick();
    
    int result = ${model_name}_inference(input, output);
    
    uint32_t end_time = HAL_GetTick();
    
    if (result == 0) {
        printf("Inference completed successfully\\n");
        printf("Execution time: %lu ms\\n", end_time - start_time);
        
        // Print first few outputs
        printf("Output (first 10 values): ");
        for (int i = 0; i < 10 && i < ${model_name}_get_output_size(); i++) {
            printf("%.3f ", output[i]);
        }
        printf("\\n");
    } else {
        printf("Inference failed with error code: %d\\n", result);
    }
    
    // Cleanup
    ${model_name}_cleanup();
    
    return result;
}

